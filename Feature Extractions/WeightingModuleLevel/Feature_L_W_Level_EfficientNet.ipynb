{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3020e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Import Required Libraries\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9372cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# DEFT Modules\n",
    "# -------------------------------------------------------------\n",
    "class LocalizationNetwork(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 8, kernel_size=7)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1, 32)  # placeholder\n",
    "        self.fc2 = nn.Linear(32, 6)\n",
    "\n",
    "        self.fc2.weight.data.zero_()\n",
    "        self.fc2.bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "        if not hasattr(self, 'computed_fc1'):\n",
    "            flattened_size = x.view(x.shape[0], -1).shape[1]\n",
    "            self.fc1 = nn.Linear(flattened_size, 32).to(x.device)\n",
    "            self.computed_fc1 = True\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        theta = self.fc2(x)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        return theta\n",
    "\n",
    "\n",
    "class WeightingModule(nn.Module):\n",
    "    def __init__(self, sigma=0.5):\n",
    "        super(WeightingModule, self).__init__()\n",
    "        self.lambda_param = nn.Parameter(torch.tensor(0.5))\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, grid):\n",
    "        dist2 = grid[..., 0] ** 2 + grid[..., 1] ** 2\n",
    "        weight = 1 + self.lambda_param * torch.exp(-dist2 / (2 * self.sigma ** 2))\n",
    "        return weight.unsqueeze(-1)\n",
    "\n",
    "\n",
    "class DEFTModule(nn.Module):\n",
    "    def __init__(self, input_channels, sigma=0.5):\n",
    "        super(DEFTModule, self).__init__()\n",
    "        self.localization = LocalizationNetwork(input_channels)\n",
    "        self.weighting = WeightingModule(sigma)\n",
    "\n",
    "    def forward(self, x):\n",
    "        theta = self.localization(x)\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        weight = self.weighting(grid)\n",
    "        x_transformed = F.grid_sample(x, grid, align_corners=False)\n",
    "\n",
    "        if x.shape[1] > 1:\n",
    "            weight = weight.expand(-1, x.shape[2], x.shape[3], x.shape[1]).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            weight = weight.permute(0, 3, 1, 2)\n",
    "\n",
    "        x_weighted = x_transformed * weight\n",
    "        return x_weighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee14bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# EfficientNet Feature Extractor with DEFT\n",
    "# -------------------------------------------------------------\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, use_deft=True):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.use_deft = use_deft\n",
    "        self.deft = DEFTModule(input_channels=3) if use_deft else None\n",
    "\n",
    "        # Load EfficientNet-B0\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_b0(weights=weights)\n",
    "\n",
    "        # Remove classifier head\n",
    "        self.backbone = nn.Sequential(\n",
    "            self.backbone.features,\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_deft:\n",
    "            x = self.deft(x)\n",
    "        x = self.backbone(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Initialize Model and Device\n",
    "# -------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = FeatureExtractor(use_deft=True).to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Image Preprocessing\n",
    "# -------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def extract_features(image_path, transform, device=device):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(image).squeeze().cpu().numpy()\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping frame: {image_path} due to error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca78268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------\n",
    "rgb_path = \"D:/Datasets/Datasets/EPIC_Kitchen/RGB/P01_04\"\n",
    "label_csv_path = \"D:/Datasets/Datasets/EPIC_Kitchen/Label/P01_04.csv\"\n",
    "output_csv = \"Feature_P01_04_EpicKitchen_EfficientNetLW.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(label_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96941f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting RGB Features Only: 100%|██████████████████████████████████████████████████| 631/631 [00:25<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Feature extraction completed. Saved to: Feature_P01_04_EpicKitchen_EfficientNetLW.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Extract RGB Features Only and Save\n",
    "# -------------------------------------------------------------\n",
    "S = 10\n",
    "features_list = []\n",
    "all_frames_rgb = sorted(os.listdir(rgb_path))[::S]\n",
    "\n",
    "for frame in tqdm(all_frames_rgb, desc=\"Extracting RGB Features Only\"):\n",
    "    frame_path = os.path.join(rgb_path, frame)\n",
    "    rgb_features = extract_features(frame_path, transform)\n",
    "\n",
    "    if rgb_features is not None:\n",
    "        frame_number = int(frame.split('_')[-1].split('.')[0])\n",
    "        label_row = labels_df[(labels_df['StartFrame'] <= frame_number) & (labels_df['EndFrame'] >= frame_number)]\n",
    "\n",
    "        if not label_row.empty:\n",
    "            action_class = label_row.iloc[0]['Action_class']\n",
    "        else:\n",
    "            action_class = 0  # default fallback\n",
    "\n",
    "        features_list.append([frame, action_class] + rgb_features.tolist())\n",
    "\n",
    "# ----------------- Save to CSV -----------------\n",
    "if len(features_list) == 0:\n",
    "    raise ValueError(\"No valid features extracted. Check paths and formats.\")\n",
    "\n",
    "columns = [\"Frame\", \"Action_class\"] + [f\"Feature_{i}\" for i in range(len(rgb_features))]\n",
    "df = pd.DataFrame(features_list, columns=columns)\n",
    "\n",
    "output_dir = os.path.dirname(output_csv)\n",
    "if output_dir:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✅ Feature extraction completed. Saved to: {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
