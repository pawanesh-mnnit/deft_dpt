{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c9d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Import Required Libraries\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import alexnet\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24aae4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class STN(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(STN, self).__init__()\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.fc_loc = nn.Linear(1, 32)  # Will be replaced dynamically\n",
    "        self.fc_initialized = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        xs = self.localization(x)\n",
    "        flattened_size = xs.view(xs.size(0), -1).shape[1]\n",
    "\n",
    "        if not self.fc_initialized:\n",
    "            self.fc_loc = nn.Linear(flattened_size, 6).to(x.device)\n",
    "            self.fc_loc.weight.data.zero_()\n",
    "            self.fc_loc.bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "            self.fc_initialized = True\n",
    "\n",
    "        xs = xs.view(xs.size(0), -1)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x_transformed = F.grid_sample(x, grid, align_corners=False)\n",
    "        return x_transformed\n",
    "\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, use_stn=True):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.use_stn = use_stn\n",
    "        self.stn = STN(input_channels=3) if use_stn else None\n",
    "\n",
    "        # ✅ Use AlexNet instead of VGG16\n",
    "        self.alexnet_model = alexnet(weights=\"IMAGENET1K_V1\").features\n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))  # Global pooling to flatten output\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_stn:\n",
    "            x = self.stn(x)\n",
    "        features = self.alexnet_model(x)\n",
    "        features = self.pooling(features)\n",
    "        return features.view(features.size(0), -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13956e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Initialize Model and Device\n",
    "# -------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "feature_extractor = FeatureExtractor(use_stn=True).to(device)\n",
    "feature_extractor.eval()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Image Preprocessing\n",
    "# -------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "def extract_features(image_path, transform, device=device):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(image).squeeze().cpu().numpy()\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping frame: {image_path} due to error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b7093ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Paths\n",
    "# -------------------------------------------------------------\n",
    "rgb_path = \"D:/Datasets/Datasets/MECCANO/RGB_Frames_Original/0005\"\n",
    "label_csv_path = \"D:/Datasets/Datasets/MECCANO/Labels_ExcelFile(1-6)/0005_csv.csv\"\n",
    "output_csv = \"Feature_0005_Meccano_AlexNet.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(label_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf2ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting RGB Features Only: 100%|██████████████████████████████████████████████████| 676/676 [00:23<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Feature extraction completed. Saved to: Feature_0005_Meccano_AlexNet.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------------\n",
    "# Extract RGB Features Only and Save\n",
    "# -------------------------------------------------------------\n",
    "S = 10\n",
    "features_list = []\n",
    "all_frames_rgb = sorted(os.listdir(rgb_path))[::S]\n",
    "\n",
    "for frame in tqdm(all_frames_rgb, desc=\"Extracting RGB Features Only\"):\n",
    "    frame_path = os.path.join(rgb_path, frame)\n",
    "    rgb_features = extract_features(frame_path, transform)\n",
    "\n",
    "    if rgb_features is not None:\n",
    "        frame_number = int(frame.split('_')[-1].split('.')[0])\n",
    "        label_row = labels_df[(labels_df['StartFrame'] <= frame_number) & (labels_df['EndFrame'] >= frame_number)]\n",
    "\n",
    "        if not label_row.empty:\n",
    "            action_class = label_row.iloc[0]['ActionLabel']\n",
    "        else:\n",
    "            action_class = 0  # default fallback\n",
    "\n",
    "        features_list.append([frame, action_class] + rgb_features.tolist())\n",
    "\n",
    "# ----------------- Save to CSV -----------------\n",
    "if len(features_list) == 0:\n",
    "    raise ValueError(\"No valid features extracted. Check paths and formats.\")\n",
    "\n",
    "columns = [\"Frame\", \"Action_class\"] + [f\"Feature_{i}\" for i in range(len(rgb_features))]\n",
    "df = pd.DataFrame(features_list, columns=columns)\n",
    "\n",
    "output_dir = os.path.dirname(output_csv)\n",
    "if output_dir:\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✅ Feature extraction completed. Saved to: {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
