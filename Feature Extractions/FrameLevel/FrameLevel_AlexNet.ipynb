{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154063e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import alexnet\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09786180",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Dropout(p=0.5, inplace=False)\n",
       "  (7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (9): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -------------------------------------------------------------\n",
    "# Load Pretrained AlexNet with 1024-D Output\n",
    "# -------------------------------------------------------------\n",
    "base_model = alexnet(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze base model parameters (optional)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Custom model: extract features and add projection layer\n",
    "alexnet_model = nn.Sequential(\n",
    "    base_model.features,\n",
    "    base_model.avgpool,\n",
    "    nn.Flatten(),\n",
    "    *list(base_model.classifier)[:5],  # Up to 4096-dim (before classifier[6])\n",
    "    nn.Linear(4096, 1024),  # Project 4096 → 1024\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "alexnet_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d981e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Define Image Transformation\n",
    "# -------------------------------------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # AlexNet expects 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Feature Extraction Function\n",
    "# -------------------------------------------------------------\n",
    "def extract_features(image_path, transform, device=device):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = alexnet_model(image).squeeze().cpu().numpy()\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping frame: {image_path} due to error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c25227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Paths to RGB and Label CSV\n",
    "# -------------------------------------------------------------\n",
    "rgb_path = \"D:/Datasets/Datasets/ADL/Frames/P_16\"\n",
    "label_csv_path = \"D:/Datasets/Datasets/ADL/Label/P_16.csv\"\n",
    "output_csv = \"Feature_AlexNet1024/Feature_P_16_ADL.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(label_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9a4c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting RGB Features: 100%|███████████████████████████████████████████████████████| 630/630 [00:17<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extraction using AlexNet completed! Saved to: Feature_AlexNet1024/Feature_P_16_ADL.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Extract Features and Save to CSV\n",
    "# -------------------------------------------------------------\n",
    "S = 40  # Sampling every 5th frame\n",
    "features_list = []\n",
    "\n",
    "all_frames = sorted(os.listdir(rgb_path))[::S]\n",
    "\n",
    "for frame in tqdm(all_frames, desc=\"Extracting RGB Features\"):\n",
    "    rgb_frame_path = os.path.join(rgb_path, frame)\n",
    "    rgb_features = extract_features(rgb_frame_path, transform, device)\n",
    "\n",
    "    if rgb_features is not None:\n",
    "        frame_number = int(frame.split('_')[-1].split('.')[0])\n",
    "        label_row = labels_df[(labels_df['StartFrame'] <= frame_number) & (labels_df['EndFrame'] >= frame_number)]\n",
    "        action_label = label_row.iloc[0]['ActionLabel'] if not label_row.empty else 0\n",
    "        features_list.append([frame, action_label] + rgb_features.tolist())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Save Features to CSV\n",
    "# -------------------------------------------------------------\n",
    "if len(features_list) == 0:\n",
    "    raise ValueError(\"No valid features extracted.\")\n",
    "\n",
    "columns = [\"Frame\", \"ActionLabel\"] + [f\"Feature_{i}\" for i in range(1024)]\n",
    "df = pd.DataFrame(features_list, columns=columns)\n",
    "os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"✅ Feature extraction using AlexNet completed! Saved to: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
