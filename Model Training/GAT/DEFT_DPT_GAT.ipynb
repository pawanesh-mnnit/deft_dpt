{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f1c6566",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f34edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b214c0",
   "metadata": {},
   "source": [
    "### Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5905f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"..Feature_with_FrameLevel/Feature_ResNet50Only/Feature_P01_04_EpicKitchen.csv\")\n",
    "action_classes = sorted(features_df[\"ActionLabel\"].unique())\n",
    "action_mapping = {action_classes[i]: i for i in range(len(action_classes))}\n",
    "features_df[\"action_class_mapped\"] = features_df[\"ActionLabel\"].map(action_mapping)\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "def process_data(df):\n",
    "    X = torch.tensor(df.iloc[:, 3:].values, dtype=torch.float32)\n",
    "    y = torch.tensor(df[\"action_class_mapped\"].values, dtype=torch.long)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = process_data(train_df)\n",
    "X_val, y_val = process_data(val_df)\n",
    "X_test, y_test = process_data(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e128e2",
   "metadata": {},
   "source": [
    "### SVSG Graph Construction using DPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f8371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_percentile_graph(X, percentile=95, device='cuda'):\n",
    "    X = X.to(device)\n",
    "    N = X.shape[0]\n",
    "    sim_matrix = F.cosine_similarity(X.unsqueeze(1), X.unsqueeze(0), dim=2)\n",
    "    threshold = torch.quantile(sim_matrix, percentile / 100)\n",
    "    adj_matrix = (sim_matrix >= threshold).float()\n",
    "    adj_matrix.fill_diagonal_(0)\n",
    "    row_indices, col_indices = torch.nonzero(adj_matrix, as_tuple=True)\n",
    "    edge_index = torch.stack([row_indices, col_indices], dim=0)\n",
    "    edge_count = edge_index.shape[1]\n",
    "    total_possible_edges = N * (N - 1)\n",
    "    return edge_index, edge_count, total_possible_edges\n",
    "\n",
    "def plot_dpt_graph(edge_index, num_nodes, title=\"DPT Graph (Circular Layout)\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import networkx as nx\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(range(1, num_nodes + 1))  \n",
    "    edges = edge_index.cpu().numpy().T\n",
    "    edges_1based = [(src + 1, dst + 1) for src, dst in edges]\n",
    "    G.add_edges_from(edges_1based)\n",
    "    pos = nx.circular_layout(G)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='lavender', edgecolors='black', node_size=100)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_color='red', font_weight='bold')\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', arrows=True, arrowsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c4a03",
   "metadata": {},
   "source": [
    "### GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "286a9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=2):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class MultiTaskLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.8):\n",
    "        super(MultiTaskLoss, self).__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, outputs, targets, features):\n",
    "        ce = self.ce_loss(outputs, targets)\n",
    "        temporal_loss = torch.mean(torch.abs(features[1:] - features[:-1]))\n",
    "        return self.alpha * ce + (1 - self.alpha) * temporal_loss\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = features_df['action_class_mapped'].nunique()\n",
    "model = GATModel(input_dim, hidden_dim, output_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "criterion = MultiTaskLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2b480",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1b17b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 1.1145 - Val Loss: 0.6019 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8406 - Recall: 0.8218 - F1-Score: 0.7857 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 2/100 - Loss: 1.0846 - Val Loss: 0.6030 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8389 - Recall: 0.8218 - F1-Score: 0.7836 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 3/100 - Loss: 1.0464 - Val Loss: 0.6112 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8764 - Recall: 0.8614 - F1-Score: 0.8334 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 4/100 - Loss: 1.0186 - Val Loss: 0.6253 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9028 - Recall: 0.8812 - F1-Score: 0.8604 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 5/100 - Loss: 1.0114 - Val Loss: 0.6394 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9028 - Recall: 0.8812 - F1-Score: 0.8583 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 6/100 - Loss: 1.0180 - Val Loss: 0.6455 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8865 - Recall: 0.8614 - F1-Score: 0.8345 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 7/100 - Loss: 1.0211 - Val Loss: 0.6399 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8949 - Recall: 0.8713 - F1-Score: 0.8438 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 8/100 - Loss: 1.0093 - Val Loss: 0.6263 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8886 - Recall: 0.8614 - F1-Score: 0.8293 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 9/100 - Loss: 0.9886 - Val Loss: 0.6119 - Top-1 Acc: 0.8515 - Top-5 Acc: 1.0000 - Precision: 0.8798 - Recall: 0.8515 - F1-Score: 0.8173 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 10/100 - Loss: 0.9750 - Val Loss: 0.6013 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8674 - Recall: 0.8416 - F1-Score: 0.8026 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 11/100 - Loss: 0.9748 - Val Loss: 0.5943 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8556 - Recall: 0.8218 - F1-Score: 0.7786 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 12/100 - Loss: 0.9775 - Val Loss: 0.5886 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8556 - Recall: 0.8218 - F1-Score: 0.7786 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 13/100 - Loss: 0.9719 - Val Loss: 0.5832 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8556 - Recall: 0.8218 - F1-Score: 0.7786 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 14/100 - Loss: 0.9580 - Val Loss: 0.5787 - Top-1 Acc: 0.8218 - Top-5 Acc: 1.0000 - Precision: 0.8556 - Recall: 0.8218 - F1-Score: 0.7786 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 15/100 - Loss: 0.9437 - Val Loss: 0.5757 - Top-1 Acc: 0.8515 - Top-5 Acc: 1.0000 - Precision: 0.8731 - Recall: 0.8515 - F1-Score: 0.8168 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 16/100 - Loss: 0.9347 - Val Loss: 0.5738 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8883 - Recall: 0.8713 - F1-Score: 0.8441 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 17/100 - Loss: 0.9301 - Val Loss: 0.5718 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8946 - Recall: 0.8812 - F1-Score: 0.8586 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 18/100 - Loss: 0.9259 - Val Loss: 0.5685 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8946 - Recall: 0.8812 - F1-Score: 0.8586 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 19/100 - Loss: 0.9186 - Val Loss: 0.5638 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8871 - Recall: 0.8713 - F1-Score: 0.8444 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 20/100 - Loss: 0.9080 - Val Loss: 0.5586 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8787 - Recall: 0.8614 - F1-Score: 0.8350 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 21/100 - Loss: 0.8962 - Val Loss: 0.5543 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8787 - Recall: 0.8614 - F1-Score: 0.8350 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 22/100 - Loss: 0.8859 - Val Loss: 0.5517 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8944 - Recall: 0.8812 - F1-Score: 0.8553 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 23/100 - Loss: 0.8781 - Val Loss: 0.5510 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8770 - Recall: 0.8614 - F1-Score: 0.8317 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 24/100 - Loss: 0.8718 - Val Loss: 0.5514 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8651 - Recall: 0.8416 - F1-Score: 0.8031 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 25/100 - Loss: 0.8653 - Val Loss: 0.5518 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8651 - Recall: 0.8416 - F1-Score: 0.8031 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 26/100 - Loss: 0.8577 - Val Loss: 0.5516 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8651 - Recall: 0.8416 - F1-Score: 0.8031 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 27/100 - Loss: 0.8493 - Val Loss: 0.5506 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8651 - Recall: 0.8416 - F1-Score: 0.8031 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 28/100 - Loss: 0.8406 - Val Loss: 0.5495 - Top-1 Acc: 0.8515 - Top-5 Acc: 1.0000 - Precision: 0.8705 - Recall: 0.8515 - F1-Score: 0.8172 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 29/100 - Loss: 0.8323 - Val Loss: 0.5485 - Top-1 Acc: 0.8416 - Top-5 Acc: 1.0000 - Precision: 0.8612 - Recall: 0.8416 - F1-Score: 0.8065 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 30/100 - Loss: 0.8251 - Val Loss: 0.5478 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8812 - Recall: 0.8614 - F1-Score: 0.8293 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 31/100 - Loss: 0.8188 - Val Loss: 0.5474 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8895 - Recall: 0.8713 - F1-Score: 0.8441 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 32/100 - Loss: 0.8129 - Val Loss: 0.5468 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8977 - Recall: 0.8812 - F1-Score: 0.8544 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 33/100 - Loss: 0.8069 - Val Loss: 0.5460 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8977 - Recall: 0.8812 - F1-Score: 0.8544 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 34/100 - Loss: 0.8008 - Val Loss: 0.5451 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8977 - Recall: 0.8812 - F1-Score: 0.8544 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 35/100 - Loss: 0.7948 - Val Loss: 0.5443 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.8977 - Recall: 0.8812 - F1-Score: 0.8544 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 36/100 - Loss: 0.7893 - Val Loss: 0.5434 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8875 - Recall: 0.8713 - F1-Score: 0.8432 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 37/100 - Loss: 0.7843 - Val Loss: 0.5426 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 38/100 - Loss: 0.7798 - Val Loss: 0.5414 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 39/100 - Loss: 0.7753 - Val Loss: 0.5400 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 40/100 - Loss: 0.7709 - Val Loss: 0.5385 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 41/100 - Loss: 0.7665 - Val Loss: 0.5370 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 42/100 - Loss: 0.7623 - Val Loss: 0.5358 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 43/100 - Loss: 0.7584 - Val Loss: 0.5350 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 44/100 - Loss: 0.7548 - Val Loss: 0.5346 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8769 - Recall: 0.8614 - F1-Score: 0.8311 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 45/100 - Loss: 0.7512 - Val Loss: 0.5345 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8760 - Recall: 0.8614 - F1-Score: 0.8358 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 46/100 - Loss: 0.7475 - Val Loss: 0.5346 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8760 - Recall: 0.8614 - F1-Score: 0.8358 - Edge Retained: 16200/162006 (10.00% sparse)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Loss: 0.7438 - Val Loss: 0.5349 - Top-1 Acc: 0.8515 - Top-5 Acc: 1.0000 - Precision: 0.8701 - Recall: 0.8515 - F1-Score: 0.8273 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 48/100 - Loss: 0.7402 - Val Loss: 0.5352 - Top-1 Acc: 0.8515 - Top-5 Acc: 1.0000 - Precision: 0.8789 - Recall: 0.8515 - F1-Score: 0.8239 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 49/100 - Loss: 0.7369 - Val Loss: 0.5354 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8895 - Recall: 0.8614 - F1-Score: 0.8360 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 50/100 - Loss: 0.7337 - Val Loss: 0.5351 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8895 - Recall: 0.8614 - F1-Score: 0.8360 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 51/100 - Loss: 0.7305 - Val Loss: 0.5344 - Top-1 Acc: 0.8614 - Top-5 Acc: 1.0000 - Precision: 0.8895 - Recall: 0.8614 - F1-Score: 0.8360 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 52/100 - Loss: 0.7274 - Val Loss: 0.5333 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8964 - Recall: 0.8713 - F1-Score: 0.8506 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 53/100 - Loss: 0.7244 - Val Loss: 0.5319 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8964 - Recall: 0.8713 - F1-Score: 0.8506 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 54/100 - Loss: 0.7212 - Val Loss: 0.5304 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8964 - Recall: 0.8713 - F1-Score: 0.8506 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 55/100 - Loss: 0.7181 - Val Loss: 0.5290 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8964 - Recall: 0.8713 - F1-Score: 0.8506 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 56/100 - Loss: 0.7151 - Val Loss: 0.5276 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 57/100 - Loss: 0.7122 - Val Loss: 0.5264 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 58/100 - Loss: 0.7093 - Val Loss: 0.5254 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 59/100 - Loss: 0.7064 - Val Loss: 0.5248 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 60/100 - Loss: 0.7035 - Val Loss: 0.5244 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 61/100 - Loss: 0.7007 - Val Loss: 0.5243 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 62/100 - Loss: 0.6979 - Val Loss: 0.5243 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 63/100 - Loss: 0.6951 - Val Loss: 0.5243 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 64/100 - Loss: 0.6924 - Val Loss: 0.5241 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.8923 - Recall: 0.8713 - F1-Score: 0.8499 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 65/100 - Loss: 0.6897 - Val Loss: 0.5238 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 66/100 - Loss: 0.6870 - Val Loss: 0.5234 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 67/100 - Loss: 0.6843 - Val Loss: 0.5229 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 68/100 - Loss: 0.6817 - Val Loss: 0.5224 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 69/100 - Loss: 0.6790 - Val Loss: 0.5218 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 70/100 - Loss: 0.6764 - Val Loss: 0.5212 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 71/100 - Loss: 0.6738 - Val Loss: 0.5206 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 72/100 - Loss: 0.6713 - Val Loss: 0.5200 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 73/100 - Loss: 0.6687 - Val Loss: 0.5194 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 74/100 - Loss: 0.6662 - Val Loss: 0.5190 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 75/100 - Loss: 0.6637 - Val Loss: 0.5187 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 76/100 - Loss: 0.6612 - Val Loss: 0.5184 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 77/100 - Loss: 0.6588 - Val Loss: 0.5181 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 78/100 - Loss: 0.6564 - Val Loss: 0.5177 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 79/100 - Loss: 0.6540 - Val Loss: 0.5174 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 80/100 - Loss: 0.6517 - Val Loss: 0.5170 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 81/100 - Loss: 0.6493 - Val Loss: 0.5166 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 82/100 - Loss: 0.6471 - Val Loss: 0.5162 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 83/100 - Loss: 0.6448 - Val Loss: 0.5156 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 84/100 - Loss: 0.6426 - Val Loss: 0.5150 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 85/100 - Loss: 0.6404 - Val Loss: 0.5144 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 86/100 - Loss: 0.6383 - Val Loss: 0.5137 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 87/100 - Loss: 0.6362 - Val Loss: 0.5131 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 88/100 - Loss: 0.6341 - Val Loss: 0.5125 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 89/100 - Loss: 0.6321 - Val Loss: 0.5119 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 90/100 - Loss: 0.6301 - Val Loss: 0.5113 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 - Loss: 0.6281 - Val Loss: 0.5106 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 92/100 - Loss: 0.6262 - Val Loss: 0.5100 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 93/100 - Loss: 0.6244 - Val Loss: 0.5094 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 94/100 - Loss: 0.6225 - Val Loss: 0.5088 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.9010 - Recall: 0.8713 - F1-Score: 0.8535 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 95/100 - Loss: 0.6207 - Val Loss: 0.5082 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.9010 - Recall: 0.8713 - F1-Score: 0.8535 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 96/100 - Loss: 0.6189 - Val Loss: 0.5075 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.9010 - Recall: 0.8713 - F1-Score: 0.8535 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 97/100 - Loss: 0.6171 - Val Loss: 0.5068 - Top-1 Acc: 0.8713 - Top-5 Acc: 1.0000 - Precision: 0.9010 - Recall: 0.8713 - F1-Score: 0.8535 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 98/100 - Loss: 0.6154 - Val Loss: 0.5061 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 99/100 - Loss: 0.6137 - Val Loss: 0.5054 - Top-1 Acc: 0.8812 - Top-5 Acc: 1.0000 - Precision: 0.9038 - Recall: 0.8812 - F1-Score: 0.8623 - Edge Retained: 16200/162006 (10.00% sparse)\n",
      "Epoch 100/100 - Loss: 0.6120 - Val Loss: 0.5046 - Top-1 Acc: 0.8911 - Top-5 Acc: 1.0000 - Precision: 0.9162 - Recall: 0.8911 - F1-Score: 0.8721 - Edge Retained: 16200/162006 (10.00% sparse)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "percentile_threshold = 95\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    edge_index, edge_count, total_possible_edges = dynamic_percentile_graph(\n",
    "        X_train, percentile=percentile_threshold, device=device)\n",
    "    edge_index = edge_index.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train.to(device), edge_index)\n",
    "    loss = criterion(output, y_train.to(device), X_train.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        edge_index_val, _, _ = dynamic_percentile_graph(\n",
    "            X_val, percentile=percentile_threshold, device=device)\n",
    "        edge_index_val = edge_index_val.to(device)\n",
    "        val_output = model(X_val.to(device), edge_index_val)\n",
    "        val_loss = criterion(val_output, y_val.to(device), X_val.to(device))\n",
    "        val_probs = torch.softmax(val_output, dim=1)\n",
    "        val_preds = val_probs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        top1_acc = (val_preds == y_val.cpu().numpy()).sum() / len(y_val)\n",
    "        precision = precision_score(y_val.cpu().numpy(), val_preds, average='weighted', zero_division=1)\n",
    "        recall = recall_score(y_val.cpu().numpy(), val_preds, average='weighted', zero_division=1)\n",
    "        f1 = f1_score(y_val.cpu().numpy(), val_preds, average='weighted', zero_division=1)\n",
    "        top5_preds = torch.topk(val_probs, 5, dim=1).indices.cpu().numpy()\n",
    "        top5_correct = sum([y in top5 for y, top5 in zip(y_val.cpu().numpy(), top5_preds)])\n",
    "        top5_acc = top5_correct / len(y_val)\n",
    "\n",
    "    sparsity_ratio = edge_count / total_possible_edges * 100\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Loss: {loss.item():.4f} - \"\n",
    "          f\"Val Loss: {val_loss.item():.4f} - \"\n",
    "          f\"Top-1 Acc: {top1_acc:.4f} - \"\n",
    "          f\"Top-5 Acc: {top5_acc:.4f} - \"\n",
    "          f\"Precision: {precision:.4f} - \"\n",
    "          f\"Recall: {recall:.4f} - \"\n",
    "          f\"F1-Score: {f1:.4f} - \"\n",
    "          f\"Edge Retained: {edge_count}/{total_possible_edges} \"\n",
    "          f\"({sparsity_ratio:.2f}% sparse)\")\n",
    "\n",
    "edge_index_final, _, _ = dynamic_percentile_graph(\n",
    "    X_train, percentile=percentile_threshold, device=device)\n",
    "plot_dpt_graph(edge_index_final, X_train.shape[0], title=f\"Final DPT Graph After {num_epochs} Epochs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
