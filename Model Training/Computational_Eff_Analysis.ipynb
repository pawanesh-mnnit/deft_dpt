{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c459fec",
   "metadata": {},
   "source": [
    "### Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39bec09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda ptflops available: True\n"
     ]
    }
   ],
   "source": [
    "import os, glob, json, csv, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torch_geometric.nn import GATConv\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    _HAS_PT_FLOPS = True\n",
    "except:\n",
    "    _HAS_PT_FLOPS = False\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device, \"ptflops available:\", _HAS_PT_FLOPS)\n",
    "\n",
    "#config--------------------\n",
    "\n",
    "rgb_path = \"../Images/\"     \n",
    "FEATURE_FOLDER = \"../Feature_with_FrameLevel/Feature_ResNet50Only/\"\n",
    "CSV_GLOB = os.path.join(FEATURE_FOLDER, \"*.csv\")\n",
    "\n",
    "# Profiling parameters\n",
    "WINDOW_SIZE = 30    # frames per window\n",
    "STRIDE = 15\n",
    "DPT_PERCENTILE = 95\n",
    "RUNS_PER_WINDOW = 20\n",
    "WARMUP = 5\n",
    "\n",
    "# Outputs\n",
    "OUT_MODULE_CSV = \"module_level_tableA.csv\"\n",
    "OUT_PER_VIDEO_SUM = \"per_video_DEFT_DPT_GAT_summary.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948d030",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42c47ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEFT and ResNet feature extractor ready.\n"
     ]
    }
   ],
   "source": [
    "class LocalizationNetwork(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 8, kernel_size=7)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 10, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(1, 32)  # temporary\n",
    "        self.fc2 = nn.Linear(32, 6)\n",
    "        self.fc2.weight.data.zero_()\n",
    "        self.fc2.bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        if not hasattr(self, 'computed_fc1'):\n",
    "            flattened_size = x.view(x.shape[0], -1).shape[1]\n",
    "            self.fc1 = nn.Linear(flattened_size, 32).to(x.device)\n",
    "            self.computed_fc1 = True\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        theta = self.fc2(x)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        return theta\n",
    "\n",
    "class WeightingModule(nn.Module):\n",
    "    def __init__(self, sigma=0.5):\n",
    "        super(WeightingModule, self).__init__()\n",
    "        self.lambda_param = nn.Parameter(torch.tensor(0.5))\n",
    "        self.sigma = sigma\n",
    "    def forward(self, grid):\n",
    "        dist2 = grid[..., 0]**2 + grid[..., 1]**2\n",
    "        weight = 1 + self.lambda_param * torch.exp(-dist2 / (2 * self.sigma ** 2))\n",
    "        return weight.unsqueeze(-1)\n",
    "\n",
    "class DEFTModule(nn.Module):\n",
    "    def __init__(self, input_channels, sigma=0.5):\n",
    "        super(DEFTModule, self).__init__()\n",
    "        self.localization = LocalizationNetwork(input_channels)\n",
    "        self.weighting = WeightingModule(sigma)\n",
    "    def forward(self, x):\n",
    "        theta = self.localization(x)\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        weight = self.weighting(grid)\n",
    "        x_transformed = F.grid_sample(x, grid, align_corners=False)\n",
    "        if x.shape[1] > 1:\n",
    "            weight = weight.expand(-1, x.shape[2], x.shape[3], x.shape[1]).permute(0, 3, 1, 2)\n",
    "        else:\n",
    "            weight = weight.permute(0, 3, 1, 2)\n",
    "        x_weighted = x_transformed * weight\n",
    "        return x_weighted\n",
    "\n",
    "\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model = torch.nn.Sequential(*list(resnet_model.children())[:-1]) \n",
    "resnet_model.eval().to(device)\n",
    "deft_model = DEFTModule(input_channels=3).to(device)\n",
    "deft_model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"DEFT and ResNet feature extractor ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3271daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, transform, device=device):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = transform(image).unsqueeze(0).to(device) \n",
    "        with torch.no_grad():\n",
    "            image = deft_model(image)                     \n",
    "            features = resnet_model(image).squeeze().cpu().numpy()  \n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping frame: {image_path} due to error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b2836",
   "metadata": {},
   "source": [
    "### DPT builder, GATModel, GFLOPs estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50a0f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, heads=2):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def dynamic_percentile_graph_cpu(X_cpu, percentile=95):\n",
    "    sim = F.cosine_similarity(X_cpu.unsqueeze(1), X_cpu.unsqueeze(0), dim=2)\n",
    "    sim = sim.clone()\n",
    "    sim.fill_diagonal_(-1.0)\n",
    "    thr = torch.quantile(sim, percentile/100.0)\n",
    "    adj = (sim >= thr).float()\n",
    "    adj.fill_diagonal_(0)\n",
    "    rows, cols = torch.nonzero(adj, as_tuple=True)\n",
    "    edge_index = torch.stack([rows.long(), cols.long()], dim=0)\n",
    "    edge_count = int(edge_index.shape[1])\n",
    "    total_possible = int(X_cpu.shape[0]*(X_cpu.shape[0]-1))\n",
    "    return edge_index, edge_count, total_possible\n",
    "\n",
    "def estimate_gat_flops(N, E, Fin, Fout, heads=2):\n",
    "    flops_proj = heads * (N * Fin * Fout)\n",
    "    flops_msg  = heads * (4 * E * Fout)\n",
    "    return (flops_proj + flops_msg) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b894ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params_m(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "\n",
    "def measure_forward_time_mem_model(model, inputs, edge_index=None, runs=RUNS_PER_WINDOW, warmup=WARMUP, device=device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max(1, warmup)):\n",
    "            if edge_index is None:\n",
    "                _ = model(inputs)\n",
    "            else:\n",
    "                _ = model(inputs, edge_index)\n",
    "    times = []\n",
    "    for _ in range(max(1, runs)):\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            if edge_index is None:\n",
    "                _ = model(inputs)\n",
    "            else:\n",
    "                _ = model(inputs, edge_index)\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.time()\n",
    "        times.append((t1 - t0) * 1000.0)\n",
    "    times = np.array(times)\n",
    "    peak_mem = None\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        with torch.no_grad():\n",
    "            if edge_index is None:\n",
    "                _ = model(inputs)\n",
    "            else:\n",
    "                _ = model(inputs, edge_index)\n",
    "        peak_mem = torch.cuda.max_memory_allocated(device) / (1024**3)\n",
    "    return float(times.mean()), float(times.std()), (float(peak_mem) if peak_mem is not None else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40b6b6",
   "metadata": {},
   "source": [
    "### Profile feature extractor (DEFT + ResNet) on 30 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7bbfbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using synthetic batch to profile DEFT+ResNet (faster, no I/O).\n",
      "Synthetic profile: {'module': 'DEFT+ResNet(synthetic)', 'params_m': 24.376737, 'gflops_per_30': None, 'time_ms': 79.40442562103271, 'time_std': 0.4828444099125987, 'peak_mem_gb': 0.5409765243530273}\n"
     ]
    }
   ],
   "source": [
    "def profile_feat_extractor_real_window(rgb_dir, frame_list, transform, runs=10, warmup=3):\n",
    "    imgs = []\n",
    "    for fname in frame_list:\n",
    "        path = os.path.join(rgb_dir, fname)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img_t = transform(img)\n",
    "        imgs.append(img_t)\n",
    "    batch = torch.stack(imgs, dim=0).to(device)  # (N,3,224,224)\n",
    "    def forward_combined(x):\n",
    "        with torch.no_grad():\n",
    "            x_deft = deft_model(x)\n",
    "            feats = resnet_model(x_deft)\n",
    "            feats = feats.view(feats.shape[0], -1)\n",
    "            return feats\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max(1,warmup)): _ = forward_combined(batch)\n",
    "    times=[]\n",
    "    for _ in range(max(1,runs)):\n",
    "        if device.type=='cuda': torch.cuda.synchronize()\n",
    "        t0=time.time()\n",
    "        with torch.no_grad():\n",
    "            _ = forward_combined(batch)\n",
    "        if device.type=='cuda': torch.cuda.synchronize()\n",
    "        t1=time.time()\n",
    "        times.append((t1-t0)*1000.0)\n",
    "    mean_ms,std_ms = float(np.mean(times)), float(np.std(times))\n",
    "    peak=None\n",
    "    if device.type=='cuda':\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        with torch.no_grad(): _ = forward_combined(batch)\n",
    "        peak = torch.cuda.max_memory_allocated(device)/(1024**3)\n",
    "    params_m = count_params_m(deft_model) + count_params_m(resnet_model)\n",
    "    gflops_resnet_30 = None\n",
    "    if _HAS_PT_FLOPS:\n",
    "        try:\n",
    "            macs, p = get_model_complexity_info(resnet_model, (3,224,224), as_strings=False, print_per_layer_stat=False, verbose=False)\n",
    "            gflops_resnet_30 = (macs/1e9) * len(frame_list)\n",
    "        except:\n",
    "            gflops_resnet_30 = None\n",
    "    gflops_deft_approx = 0.01\n",
    "    total_gflops_30 = (gflops_resnet_30 or 0.0) + gflops_deft_approx\n",
    "    return {\"module\":\"DEFT+ResNet\",\"params_m\":params_m,\"gflops_per_30\":total_gflops_30,\"time_ms\":mean_ms,\"time_std\":std_ms,\"peak_mem_gb\":peak}\n",
    "\n",
    "ft_res = None\n",
    "if os.path.isdir(rgb_path):\n",
    "    frames_sorted = sorted(os.listdir(rgb_path))\n",
    "    if len(frames_sorted) >= WINDOW_SIZE:\n",
    "        sample_files = frames_sorted[:WINDOW_SIZE]\n",
    "        try:\n",
    "            ft_res = profile_feat_extractor_real_window(rgb_path, sample_files, transform, runs=10, warmup=3)\n",
    "            print(\"Real DEFT+ResNet profile:\", ft_res)\n",
    "        except Exception as e:\n",
    "            print(\"Real profiling failed:\", e)\n",
    "            ft_res = None\n",
    "\n",
    "if ft_res is None:\n",
    "    print(\"Using synthetic batch to profile DEFT+ResNet (faster, no I/O).\")\n",
    "    def profile_feat_extractor_synthetic(runs=10, warmup=3):\n",
    "        batch = torch.randn(WINDOW_SIZE,3,224,224).to(device)\n",
    "        def forward_combined(x):\n",
    "            with torch.no_grad():\n",
    "                x_deft = deft_model(x)\n",
    "                feats = resnet_model(x_deft)\n",
    "                feats = feats.view(feats.shape[0], -1)\n",
    "                return feats\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max(1,warmup)): _ = forward_combined(batch)\n",
    "        times=[]\n",
    "        for _ in range(max(1,runs)):\n",
    "            if device.type=='cuda': torch.cuda.synchronize()\n",
    "            t0=time.time()\n",
    "            with torch.no_grad(): _ = forward_combined(batch)\n",
    "            if device.type=='cuda': torch.cuda.synchronize()\n",
    "            t1=time.time()\n",
    "            times.append((t1-t0)*1000.0)\n",
    "        mean_ms,std_ms = float(np.mean(times)), float(np.std(times))\n",
    "        peak=None\n",
    "        if device.type=='cuda':\n",
    "            torch.cuda.reset_peak_memory_stats(device)\n",
    "            with torch.no_grad(): _ = forward_combined(batch)\n",
    "            peak = torch.cuda.max_memory_allocated(device)/(1024**3)\n",
    "        params_m = count_params_m(deft_model) + count_params_m(resnet_model)\n",
    "        return {\"module\":\"DEFT+ResNet(synthetic)\",\"params_m\":params_m,\"gflops_per_30\":None,\"time_ms\":mean_ms,\"time_std\":std_ms,\"peak_mem_gb\":peak}\n",
    "    ft_res = profile_feat_extractor_synthetic(runs=10, warmup=3)\n",
    "    print(\"Synthetic profile:\", ft_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe2c21",
   "metadata": {},
   "source": [
    "### window features (from real frames if available) and profile DPT & GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04853d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature window shape: torch.Size([30, 2048])\n",
      "DPT edges: 46 DPT CPU time (ms): 6.851\n",
      "GAT time (ms): 2.198 GFLOPs: 0.015776 peak GB: 0.2151031494140625\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(rgb_path) and len(os.listdir(rgb_path)) >= WINDOW_SIZE:\n",
    "    sample_files = sorted(os.listdir(rgb_path))[:WINDOW_SIZE]\n",
    "    # extract features (this loops DEFT+ResNet for each frame -> can be slow)\n",
    "    feats = []\n",
    "    for f in sample_files:\n",
    "        fp = os.path.join(rgb_path, f)\n",
    "        feat = extract_features(fp, transform, device)  # numpy array\n",
    "        if feat is None:\n",
    "            feat = np.random.randn(2048)\n",
    "        feats.append(torch.tensor(feat, dtype=torch.float32))\n",
    "    X_window_cpu = torch.stack(feats, dim=0)  # CPU tensor\n",
    "else:\n",
    "    # fallback synthetic features\n",
    "    X_window_cpu = torch.randn(WINDOW_SIZE, 2048)\n",
    "\n",
    "print(\"Feature window shape:\", X_window_cpu.shape)\n",
    "\n",
    "# DPT\n",
    "edge_index_cpu, edge_count, tot = dynamic_percentile_graph_cpu(X_window_cpu, percentile=DPT_PERCENTILE)\n",
    "t0=time.time(); _ , ec, _ = dynamic_percentile_graph_cpu(X_window_cpu, percentile=DPT_PERCENTILE); t1=time.time()\n",
    "dpt_cpu_ms = (t1 - t0) * 1000.0\n",
    "print(\"DPT edges:\", edge_count, \"DPT CPU time (ms):\", round(dpt_cpu_ms,3))\n",
    "\n",
    "# GAT profiling\n",
    "gat_model = GATModel(input_dim=X_window_cpu.shape[1], hidden_dim=128, output_dim=10, heads=2).to(device)\n",
    "X_dev = X_window_cpu.to(device)\n",
    "edge_dev = edge_index_cpu.long().to(device)\n",
    "gat_t_mean, gat_t_std, gat_peak = measure_forward_time_mem_model(gat_model, X_dev, edge_index=edge_dev, runs=50, warmup=10, device=device)\n",
    "gflops_gat = estimate_gat_flops(N=X_window_cpu.shape[0], E=edge_count, Fin=X_window_cpu.shape[1], Fout=128, heads=2)\n",
    "print(\"GAT time (ms):\", round(gat_t_mean,3), \"GFLOPs:\", round(gflops_gat,6), \"peak GB:\", gat_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0630780e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved module-level metrics to module_level_tableA.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Module': 'DEFT+ResNet(synthetic)',\n",
       "  'Params_M': 24.377,\n",
       "  'GFLOPs_per_30': None,\n",
       "  'Time_ms': 79.404,\n",
       "  'Time_std_ms': 0.483,\n",
       "  'GPU_Mem_GB': 0.540977},\n",
       " {'Module': 'DPT (CPU)',\n",
       "  'Params_M': 0.0,\n",
       "  'GFLOPs_per_30': 0.0,\n",
       "  'Time_ms': 6.851,\n",
       "  'Time_std_ms': 0.0,\n",
       "  'GPU_Mem_GB': None},\n",
       " {'Module': 'GAT',\n",
       "  'Params_M': 0.528,\n",
       "  'GFLOPs_per_30': 0.015776,\n",
       "  'Time_ms': 2.198,\n",
       "  'Time_std_ms': 0.797,\n",
       "  'GPU_Mem_GB': 0.215103},\n",
       " {'Module': 'FullPipeline',\n",
       "  'Params_M': 24.904,\n",
       "  'GFLOPs_per_30': 0.015776,\n",
       "  'Time_ms': 88.454,\n",
       "  'Time_std_ms': None,\n",
       "  'GPU_Mem_GB': 0.540977}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8 - Compose module-level rows and save CSV for Table A\n",
    "module_rows = []\n",
    "feat_row = {\n",
    "    \"Module\": ft_res[\"module\"] if \"module\" in ft_res else \"DEFT+ResNet\",\n",
    "    \"Params_M\": round(ft_res[\"params_m\"], 3) if ft_res.get(\"params_m\") is not None else None,\n",
    "    \"GFLOPs_per_30\": round(ft_res[\"gflops_per_30\"], 6) if ft_res.get(\"gflops_per_30\") is not None else None,\n",
    "    \"Time_ms\": round(ft_res[\"time_ms\"], 3),\n",
    "    \"Time_std_ms\": round(ft_res[\"time_std\"],3) if ft_res.get(\"time_std\") else round(ft_res.get(\"time_std\",0.0),3),\n",
    "    \"GPU_Mem_GB\": round(ft_res[\"peak_mem_gb\"],6) if ft_res.get(\"peak_mem_gb\") is not None else None\n",
    "}\n",
    "module_rows.append(feat_row)\n",
    "\n",
    "dpt_row = {\"Module\":\"DPT (CPU)\",\"Params_M\":0.0,\"GFLOPs_per_30\":0.0,\"Time_ms\":round(dpt_cpu_ms,3),\"Time_std_ms\":0.0,\"GPU_Mem_GB\":None}\n",
    "module_rows.append(dpt_row)\n",
    "\n",
    "gat_row = {\"Module\":\"GAT\",\"Params_M\": round(count_params_m(gat_model),3),\"GFLOPs_per_30\":round(gflops_gat,6),\"Time_ms\":round(gat_t_mean,3),\"Time_std_ms\":round(gat_t_std,3),\"GPU_Mem_GB\": round(gat_peak,6) if gat_peak is not None else None}\n",
    "module_rows.append(gat_row)\n",
    "\n",
    "full_time = (ft_res[\"time_ms\"] or 0.0) + dpt_cpu_ms + gat_t_mean\n",
    "full_gflops = (ft_res[\"gflops_per_30\"] or 0.0) + gflops_gat if ft_res.get(\"gflops_per_30\") is not None else gflops_gat\n",
    "full_params = round(count_params_m(deft_model) + count_params_m(resnet_model) + count_params_m(gat_model),3)\n",
    "full_peak = max(ft_res.get(\"peak_mem_gb\") or 0.0, gat_peak or 0.0)\n",
    "full_row = {\"Module\":\"FullPipeline\",\"Params_M\": full_params,\"GFLOPs_per_30\": round(full_gflops,6),\"Time_ms\":round(full_time,3),\"Time_std_ms\":None,\"GPU_Mem_GB\": round(full_peak,6)}\n",
    "module_rows.append(full_row)\n",
    "\n",
    "# Save CSV\n",
    "with open(OUT_MODULE_CSV, \"w\", newline='') as fh:\n",
    "    fieldnames = [\"Module\",\"Params_M\",\"GFLOPs_per_30\",\"Time_ms\",\"Time_std_ms\",\"GPU_Mem_GB\"]\n",
    "    writer = csv.DictWriter(fh, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for r in module_rows:\n",
    "        writer.writerow(r)\n",
    "\n",
    "print(\"Saved module-level metrics to\", OUT_MODULE_CSV)\n",
    "module_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb9fc4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 CSV files for profiling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c99e35b93d4762b9689c551c31d85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Profiling CSV videos:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-video summary to per_video_DEFT_DPT_GAT_summary.csv\n",
      "Mean total time (ms): 92.67303546269734 Mean GFLOPs: 0.015760384\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 - Multi-video profiling (fast mode: use first WINDOW_SIZE features from each CSV)\n",
    "csv_files = sorted(glob.glob(CSV_GLOB))\n",
    "print(\"Found\", len(csv_files), \"CSV files for profiling.\")\n",
    "\n",
    "per_video_summaries = []\n",
    "for csv_path in tqdm(csv_files, desc=\"Profiling CSV videos\"):\n",
    "    try:\n",
    "        df_vid = pd.read_csv(csv_path)\n",
    "        # try to extract feature columns - heuristics (if features stored)\n",
    "        # If your CSVs already contain extracted features, use them.\n",
    "        # Here we try columns starting at index 4 (Frame, Verb, Noun, Action -> rest are features)\n",
    "        if df_vid.shape[1] > 4:\n",
    "            feat_cols = df_vid.columns[4:]\n",
    "            X_all = torch.tensor(df_vid[feat_cols].values, dtype=torch.float32)\n",
    "            if X_all.shape[0] < WINDOW_SIZE:\n",
    "                continue\n",
    "            X_win = X_all[:WINDOW_SIZE]\n",
    "        else:\n",
    "            # If CSV doesn't have features, skip (or you could run extract_features on raw frames)\n",
    "            continue\n",
    "\n",
    "        # DPT\n",
    "        t0=time.time(); edge_idx, ecount, tot = dynamic_percentile_graph_cpu(X_win, percentile=DPT_PERCENTILE); t1=time.time()\n",
    "        dpt_time = (t1 - t0)*1000.0\n",
    "\n",
    "        # GAT profiling per window (we measure one window; assume repeated per windows)\n",
    "        gat_tmp = GATModel(input_dim=X_win.shape[1], hidden_dim=128, output_dim=10, heads=2).to(device)\n",
    "        Xt = X_win.to(device); edge_dev = edge_idx.long().to(device)\n",
    "        gat_t, gat_std, gat_peak = measure_forward_time_mem_model(gat_tmp, Xt, edge_index=edge_dev, runs=20, warmup=5, device=device)\n",
    "        gflops_gat_win = estimate_gat_flops(N=X_win.shape[0], E=ecount, Fin=X_win.shape[1], Fout=128, heads=2)\n",
    "\n",
    "        # For feature extraction time we use ft_res measured earlier as representative per-window time\n",
    "        feat_time = ft_res[\"time_ms\"]\n",
    "        feat_gflops = ft_res[\"gflops_per_30\"] or 0.0\n",
    "\n",
    "        total_time = feat_time + dpt_time + gat_t\n",
    "        total_gflops = feat_gflops + gflops_gat_win\n",
    "\n",
    "        per_video_summaries.append({\n",
    "            \"video_id\": os.path.splitext(os.path.basename(csv_path))[0],\n",
    "            \"total_time_ms\": float(total_time),\n",
    "            \"total_gflops\": float(total_gflops),\n",
    "            \"avg_edges\": int(ecount),\n",
    "            \"max_peak_mem_gb\": float(gat_peak or 0.0)\n",
    "        })\n",
    "    except Exception as ex:\n",
    "        print(\"Skipping\", csv_path, \"due to:\", ex)\n",
    "\n",
    "# Save per-video summary\n",
    "pd.DataFrame(per_video_summaries).to_csv(OUT_PER_VIDEO_SUM, index=False)\n",
    "print(\"Saved per-video summary to\", OUT_PER_VIDEO_SUM)\n",
    "if per_video_summaries:\n",
    "    arr = pd.DataFrame(per_video_summaries)\n",
    "    print(\"Mean total time (ms):\", arr[\"total_time_ms\"].mean(), \"Mean GFLOPs:\", arr[\"total_gflops\"].mean())\n",
    "else:\n",
    "    print(\"No per-video summaries generated. Check CSV contents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "573e5630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across 3 videos: Mean per-video time = 92.67 ms (std = 1.29), Mean GFLOPs = 0.016 (std = 0.000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computational Efficiency Analysis. We profiled module-level and per-video efficiency for the DEFT-DPT-GAT pipeline.\n",
      "Module-level results saved in: module_level_tableA.csv\n",
      "Per-video aggregated results saved in: per_video_DEFT_DPT_GAT_summary.csv\n",
      "Profiling device: NVIDIA GeForce RTX 4050 Laptop GPU, PyTorch 2.4.1+cu118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 - Aggregation and plotting\n",
    "if os.path.exists(OUT_PER_VIDEO_SUM):\n",
    "    summary_df = pd.read_csv(OUT_PER_VIDEO_SUM)\n",
    "    mean_time = summary_df[\"total_time_ms\"].mean()\n",
    "    std_time = summary_df[\"total_time_ms\"].std()\n",
    "    mean_gflops = summary_df[\"total_gflops\"].mean()\n",
    "    std_gflops = summary_df[\"total_gflops\"].std()\n",
    "    print(f\"Across {len(summary_df)} videos: Mean per-video time = {mean_time:.2f} ms (std = {std_time:.2f}), Mean GFLOPs = {mean_gflops:.3f} (std = {std_gflops:.3f})\")\n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(summary_df[\"total_time_ms\"]/1000.0, bins=20, kde=True)\n",
    "    plt.xlabel(\"Per-video inference time (s)\")\n",
    "    plt.title(\"Per-video inference time distribution\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Per-video summary file not found.\")\n",
    "    \n",
    "# Manuscript snippet\n",
    "gpu_info = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "snippet = f\"\"\"\n",
    "Computational Efficiency Analysis. We profiled module-level and per-video efficiency for the DEFT-DPT-GAT pipeline.\n",
    "Module-level results saved in: {OUT_MODULE_CSV}\n",
    "Per-video aggregated results saved in: {OUT_PER_VIDEO_SUM}\n",
    "Profiling device: {gpu_info}, PyTorch {torch.__version__}\n",
    "\"\"\"\n",
    "print(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ef95d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ptflops\n",
      "  Obtaining dependency information for ptflops from https://files.pythonhosted.org/packages/11/66/3eea7b5f6cc3f6ae7acb125ef82c083d9bb759c7e43fd333cb39eb1e1cfe/ptflops-0.7.5-py3-none-any.whl.metadata\n",
      "  Downloading ptflops-0.7.5-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from ptflops) (2.4.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from torch>=2.0->ptflops) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.0->ptflops) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pawanesh\\anaconda3\\lib\\site-packages (from sympy->torch>=2.0->ptflops) (1.3.0)\n",
      "Downloading ptflops-0.7.5-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: ptflops\n",
      "Successfully installed ptflops-0.7.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --proxy http://edcguest:edcguest@172.31.100.25:3128 ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9e8a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet GFLOPs per frame: 4.130387968 GFLOPs; per 30 frames: 123.91163904\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "# resnet_model is your feature extractor WITHOUT the final FC (sequential children[:-1])\n",
    "macs, params = get_model_complexity_info(resnet_model, (3,224,224), as_strings=False, print_per_layer_stat=False, verbose=False)\n",
    "gflops_per_frame = macs / 1e9\n",
    "gflops_30 = gflops_per_frame * 30\n",
    "print(\"ResNet GFLOPs per frame:\", gflops_per_frame, \"GFLOPs; per 30 frames:\", gflops_30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
